1. Three of the pitfalls listed in the text are Race Conditions, Strangled Scaling, and Deadlocks.
Briefly describe what each of these pitfalls and how you might detect their presence in your code.

Race Conditions: this is when two or more threads are racing to use the same data. If one thread gets to use the data twice in a row or faster than the other threads, incorrect results can result.
Detection comes by running the code multiple times and seeing nondeterministic and incorrect results. Nondeterministic does not in and of itself imply a race condition, but incorrect non-determinism does.

Strangled Scaling: This is when some critical set of operations is locked and can only be used by one thread at a time. This results in seemingly parallel code becoming serial.
Detection comes by realizing that a serial version of your code and a parallel version run in just about the same time, with the parallel version perhaps being longer because of overhead.

Deadlocks: This is when two or more threads are waiting for held or required locks to be released, and therefore cannot proceed. This makes the program stop and get stuck at some execution point.
Detection comes by a program appearing to stop, no more prints, no progression, just dead silence.

2. What is load imbalance? On Tuesday we talked a bunch about how we might model parallel performance, does load imbalance break/change/complicate reasoning about performance in these models?

Load imbalance is when because of task scheduling or data dependancy, one core has to do a lot more work than the other cores. When this happens, The FLOPS metric we talked about on Monday becomes less useful.
Even if the total FLOPS is pretty high, this tells us nothing about load distribution, and the system could get a lot more FLOPS if the tasks were distributed evenly.
